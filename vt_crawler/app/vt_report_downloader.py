import requests
import json
import random
import logging
import time
import os
from tor_init import TorInit
import configparser
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
parpath = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))
config = configparser.ConfigParser()
config.read(parpath + "/config.ini")
TXT_PATH = config.get("filepath", "txt_path")


class VTReportDownloader(object):

    def __init__(self, _url_list=[]):
        self.url_list = _url_list
        self.TorInit = TorInit(socks_port=9050)
        self.TorInit._startTorProxy()
        self.user_agent = ''
        self.proxies = {
            # 'http': 'socks5h://127.0.0.1:9050',
            'https': 'socks5h://127.0.0.1:9050'
        }

    def _sys_sleep(self):
        u = random.uniform(0, 0.25)
        logging.info('system sleeps {} seconds...'.format(u))
        time.sleep(u)

    def get_page_source(self, url):
        if url is None:
            return None
        s = requests.Session()
        s.proxies = self.proxies
        headers = {
            'User-Agent': self.user_agent,
        }
        # Make the HTTP request through the session.
        r = s.get(url, headers=headers)
        # r = s.get(url)
        # Check if the proxy was indeed used (the text should contain the proxy IP).
        if r.status_code == 200:
            r.encoding = 'utf-8'
            html_contnet = r.text
            logging.info('Report downloaded.')
            return html_contnet
        return None

    def save_report_2_txt(self, url):
        json_response = self.get_page_source(url)
        if json_response is None:
            logging.info('json_response is None.')
        # self._sys_sleep()
        if json_response is not None:
            sha256 = url.split('/')[-1]
            with open('{}.txt'.format(TXT_PATH + sha256), 'w') as f:
                f.write(json_response)

    def batch_save_report_2_txt(self):
        for i, u in enumerate(self.url_list):
            if i % 1000 == 0:
                print(i, 'th done.')

            logging.info('crawling vt report: {} ...'.format(u))
            json_response = self.get_page_source(u)
            # self._sys_sleep()
            if json_response is not None:
                sha256 = u.split('/')[-1]
                with open('{}.txt'.format(TXT_PATH + sha256), 'w') as f:
                    f.write(json_response)
            else:
                logging.info('json_response is None.')
                return 1


def crawl_malware_5f_report():

    done = [file.replace('.txt', '') for file in os.listdir(TXT_PATH)]

    sha_list = [sha.replace('.danger', '') for sha in open(parpath + '/malware_hash_5F.txt', 'r').read().split('\n')]
    sha_list = [file for file in sha_list if file not in done]
    _urls = ['https://www.virustotal.com/ui/files/{}'.format(sha256) for sha256 in sha_list]

    # crawl undone report data and save to a txt file
    test = VTReportDownloader(_url_list=_urls)
    test.batch_save_report_2_txt()


if __name__ == '__main__':

    # # sha256 = '494688f1044469797c5b889b81a98bc1b43a5c384984fd3d35c1656ea8bfd4e4'
    # # sha_list = ['3b77d8b231e5394831a06ee9e715428267907dee2a9b851f90cd6b841580c73d', '494688f1044469797c5b889b81a98bc1b43a5c384984fd3d35c1656ea8bfd4e4']
    # sha_list = open(parpath + '/malware_hash_5F.txt', 'r').read().split('\n')
    # _urls = ['https://www.virustotal.com/ui/files/{}'.format(sha256.replace('.danger', '')) for sha256 in sha_list]
    # # crawl report data and save to a txt file
    # test = VTReportDownloader(_url_list=_urls)
    # test.batch_save_report_2_txt()

    # # test for api checking
    # file_hash = '3b77d8b231e5394831a06ee9e715428267907dee2a9b851f90cd6b841580c73d'
    # _url = 'https://www.virustotal.com/ui/files/{}'.format(file_hash)

    # test = VTReportDownloader(_url_list=_url)
    # report = test.get_page_source(_url)
    # report = json.loads(report)

    # # unique_text_md5_set = set()

    # sec = report['data']['attributes']['pe_info']['sections']

    # try:
    #     if sec[0]['name'] == '.text':
    #         print('true')
    #         md5 = sec[0]['md5']
    #         if md5 not in unique_text_md5_set:
    #             unique_text_md5_set.add(md5)
    #             print('new md5 added.')
    # except:
    #     print('no text md5.')
    #     pass

    # print(unique_text_md5_set)
    crawl_malware_5f_report()
